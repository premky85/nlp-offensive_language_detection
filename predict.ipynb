{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03f1751845c0757013a0c9d603ff0da24a1cc182237aa8352b83331221a2726aa",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3f1751845c0757013a0c9d603ff0da24a1cc182237aa8352b83331221a2726aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models.models import TextClassificationNet\n",
    "from models.utils.data_loader import TextDataloader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(data, model_name, weights_path):\n",
    "    ''' \n",
    "    Predict function for text classification\n",
    "\n",
    "    ----------------\n",
    "    INPUTS:\n",
    "    data: Pandas.DataFrame - text column named 'text', label column named 'class' with possible values [0, 1, 2] (0 - normal language, 1 - hate speech, 2 - offensive language)\n",
    "    model_name: String - possible values ['bert', 'csebert', 'xlmr']\n",
    "    weights_path: String - path to weights file\n",
    "\n",
    "    ----------------\n",
    "    OUTPUTS:\n",
    "    preds: List - list of softmax predictions for each input text\n",
    "    '''\n",
    "    preds = []\n",
    "\n",
    "    text_dataloader = TextDataloader(seq_length=128, language_model=model_name)\n",
    "    tcn = TextClassificationNet(seq_length=128, language_model=model_name)\n",
    "    model = tcn.get_model()\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    bs = 64\n",
    "    with tqdm(total=data.shape[0] // bs) as pbar:\n",
    "        for i,rows in data.groupby(np.arange(len(data))//bs):\n",
    "            pbar.update(1)\n",
    "            tokens, masks = zip(*map(text_dataloader.tokenize, rows['text'].to_numpy()))\n",
    "            if len(masks) > 1 and len(tokens) > 1:\n",
    "                tokens, masks = tf.squeeze(tf.stack(tokens)), tf.squeeze(tf.stack(masks))\n",
    "\n",
    "            predicted = model.predict([tokens, masks])\n",
    "            preds += list(predicted)\n",
    "\n",
    "    return preds\n",
    "\n",
    "def evaluate(labels, predictions, name='generic_network'):\n",
    "    print('=================== ' + name + ' ===================\\n')\n",
    "    print(classification_report(labels, predictions, digits=3))\n",
    "    print('\\n\\n')\n",
    "\n",
    "def ensemble_voting(model_preds):\n",
    "    ''' \n",
    "    Combine predictions for ensemble voting\n",
    "\n",
    "    ----------------\n",
    "    INPUTS:\n",
    "    model_preds: List - 3d list of softmax predictions for each model contributing to voting\n",
    "\n",
    "    ----------------\n",
    "    OUTPUTS:\n",
    "    preds: List - 1d list of predictions\n",
    "    '''\n",
    "\n",
    "    return (np.sum(model_preds, axis=0) / len(model_preds)).argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create Pandas DataFrame with text column named 'text' and labels column names 'class\n",
    "\n",
    "df = None\n",
    "\n",
    "# base = '/path/to/folder/with/preprocessed/data/'\n",
    "\n",
    "'''\n",
    "If you wish to split training data to train and test set uncomment following lines:\n",
    "'''\n",
    "\n",
    "# path = [base + 'fox_news_comments_preprocessed.csv', base + 'gab_preprocessed.csv', base + 'reddit_preprocessed.csv', base + 'white_supremacist_forum_preprocessed.csv', base + 'twitter_preprocessed.csv', base + 'slo_twitter_preprocessed.csv']\n",
    "# text_column_names = ['text', 'text', 'text', 'text', 'tweet', 'tweet']\n",
    "# label_column_names = ['class', 'class', 'class', 'class', 'class', 'class']\n",
    "# dataloader = TextDataloader(seq_length=SEQ_LENGTH)\n",
    "# dataloader.load_data(path, text_column_name=text_column_names, label_column_name=label_column_names)\n",
    "# df = dataloader.get_test_data() \n",
    "\n",
    "'''\n",
    "If you wish to use single .csv file for testing uncomment following line:\n",
    "'''\n",
    "\n",
    "# df = pd.read_csv(base + 'slo_test_data_preprocessed.csv')\n",
    "\n",
    "labels = df['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2it [00:03,  1.59s/it]\n",
      "2it [00:02,  1.37s/it]\n",
      "2it [00:06,  3.10s/it]=================== Ensemble ===================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.304     1.000     0.467        28\n",
      "           1      0.333     0.030     0.056        33\n",
      "           2      0.000     0.000     0.000        34\n",
      "\n",
      "    accuracy                          0.305        95\n",
      "   macro avg      0.213     0.343     0.174        95\n",
      "weighted avg      0.205     0.305     0.157        95\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=================== mBERT ===================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.277     0.821     0.414        28\n",
      "           1      0.167     0.061     0.089        33\n",
      "           2      0.000     0.000     0.000        34\n",
      "\n",
      "    accuracy                          0.263        95\n",
      "   macro avg      0.148     0.294     0.168        95\n",
      "weighted avg      0.140     0.263     0.153        95\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=================== CroSloEngualBERT ===================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.308     1.000     0.471        28\n",
      "           1      0.250     0.030     0.054        33\n",
      "           2      0.000     0.000     0.000        34\n",
      "\n",
      "    accuracy                          0.305        95\n",
      "   macro avg      0.186     0.343     0.175        95\n",
      "weighted avg      0.178     0.305     0.157        95\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=================== XLMr ===================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.352     0.679     0.463        28\n",
      "           1      0.444     0.485     0.464        33\n",
      "           2      0.600     0.088     0.154        34\n",
      "\n",
      "    accuracy                          0.400        95\n",
      "   macro avg      0.465     0.417     0.360        95\n",
      "weighted avg      0.473     0.400     0.353        95\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/premk/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mbert_predictions = predict(df, model_name='bert', weights_path='/path/to/weights/file.h5')\n",
    "csebert_predictions = predict(df, model_name='csebert', weights_path='/path/to/weights/file.h5')\n",
    "xlmr_predictions = predict(df, model_name='xlmr', weights_path='/path/to/weights/file.h5')\n",
    "\n",
    "mbert_preds = np.array(mbert_predictions).argmax(axis=-1)\n",
    "evaluate(labels, mbert_preds, 'mBERT')\n",
    "\n",
    "csebert_preds = np.array(csebert_predictions).argmax(axis=-1)\n",
    "evaluate(labels, csebert_preds, 'CroSloEngualBERT')\n",
    "\n",
    "xlmr_preds = np.array(xlmr_predictions).argmax(axis=-1)\n",
    "evaluate(labels, xlmr_preds, 'XLMr')\n",
    "\n",
    "ensemble_preds = ensemble_voting([mbert_predictions, csebert_predictions, xlmr_predictions])\n",
    "evaluate(labels, ensemble_preds, 'Ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}